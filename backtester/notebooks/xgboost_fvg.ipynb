{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f15d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryIdx</th>\n",
       "      <th>ExitIdx</th>\n",
       "      <th>Direction</th>\n",
       "      <th>EntryPrice</th>\n",
       "      <th>ExitPrice</th>\n",
       "      <th>Size</th>\n",
       "      <th>SL</th>\n",
       "      <th>TP</th>\n",
       "      <th>PnL</th>\n",
       "      <th>Commission</th>\n",
       "      <th>...</th>\n",
       "      <th>run_sortino</th>\n",
       "      <th>run_calmar</th>\n",
       "      <th>run_mdd_pct</th>\n",
       "      <th>run_trades</th>\n",
       "      <th>run_win_rate_pct</th>\n",
       "      <th>run_profit_factor</th>\n",
       "      <th>run_sqn</th>\n",
       "      <th>run_expectancy_pct</th>\n",
       "      <th>buy_hold_return_pct</th>\n",
       "      <th>run_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3014</td>\n",
       "      <td>9121</td>\n",
       "      <td>1</td>\n",
       "      <td>211.18</td>\n",
       "      <td>209.85328</td>\n",
       "      <td>8.0</td>\n",
       "      <td>209.85328</td>\n",
       "      <td>287.1232</td>\n",
       "      <td>-10.61376</td>\n",
       "      <td>6.736532</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907327</td>\n",
       "      <td>-2.581558</td>\n",
       "      <td>-9.9907</td>\n",
       "      <td>77</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>-0.286464</td>\n",
       "      <td>-0.132974</td>\n",
       "      <td>-33.514111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13353</td>\n",
       "      <td>13610</td>\n",
       "      <td>-1</td>\n",
       "      <td>188.52</td>\n",
       "      <td>189.68130</td>\n",
       "      <td>10.0</td>\n",
       "      <td>189.68130</td>\n",
       "      <td>120.6720</td>\n",
       "      <td>-11.61300</td>\n",
       "      <td>7.564026</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907327</td>\n",
       "      <td>-2.581558</td>\n",
       "      <td>-9.9907</td>\n",
       "      <td>77</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>-0.286464</td>\n",
       "      <td>-0.132974</td>\n",
       "      <td>-33.514111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13620</td>\n",
       "      <td>13648</td>\n",
       "      <td>1</td>\n",
       "      <td>191.58</td>\n",
       "      <td>190.43052</td>\n",
       "      <td>9.0</td>\n",
       "      <td>190.43052</td>\n",
       "      <td>260.5488</td>\n",
       "      <td>-10.34532</td>\n",
       "      <td>6.876189</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907327</td>\n",
       "      <td>-2.581558</td>\n",
       "      <td>-9.9907</td>\n",
       "      <td>77</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>-0.286464</td>\n",
       "      <td>-0.132974</td>\n",
       "      <td>-33.514111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19113</td>\n",
       "      <td>19261</td>\n",
       "      <td>1</td>\n",
       "      <td>187.53</td>\n",
       "      <td>186.47440</td>\n",
       "      <td>10.0</td>\n",
       "      <td>186.47440</td>\n",
       "      <td>255.1360</td>\n",
       "      <td>-10.55600</td>\n",
       "      <td>7.480088</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907327</td>\n",
       "      <td>-2.581558</td>\n",
       "      <td>-9.9907</td>\n",
       "      <td>77</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>-0.286464</td>\n",
       "      <td>-0.132974</td>\n",
       "      <td>-33.514111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21857</td>\n",
       "      <td>21857</td>\n",
       "      <td>1</td>\n",
       "      <td>203.87</td>\n",
       "      <td>202.61696</td>\n",
       "      <td>9.0</td>\n",
       "      <td>202.61696</td>\n",
       "      <td>277.2224</td>\n",
       "      <td>-11.27736</td>\n",
       "      <td>7.316765</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.907327</td>\n",
       "      <td>-2.581558</td>\n",
       "      <td>-9.9907</td>\n",
       "      <td>77</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>0.778577</td>\n",
       "      <td>-0.286464</td>\n",
       "      <td>-0.132974</td>\n",
       "      <td>-33.514111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EntryIdx  ExitIdx  Direction  EntryPrice  ExitPrice  Size         SL  \\\n",
       "0      3014     9121          1      211.18  209.85328   8.0  209.85328   \n",
       "1     13353    13610         -1      188.52  189.68130  10.0  189.68130   \n",
       "2     13620    13648          1      191.58  190.43052   9.0  190.43052   \n",
       "3     19113    19261          1      187.53  186.47440  10.0  186.47440   \n",
       "4     21857    21857          1      203.87  202.61696   9.0  202.61696   \n",
       "\n",
       "         TP       PnL  Commission  ... run_sortino run_calmar  run_mdd_pct  \\\n",
       "0  287.1232 -10.61376    6.736532  ...   -1.907327  -2.581558      -9.9907   \n",
       "1  120.6720 -11.61300    7.564026  ...   -1.907327  -2.581558      -9.9907   \n",
       "2  260.5488 -10.34532    6.876189  ...   -1.907327  -2.581558      -9.9907   \n",
       "3  255.1360 -10.55600    7.480088  ...   -1.907327  -2.581558      -9.9907   \n",
       "4  277.2224 -11.27736    7.316765  ...   -1.907327  -2.581558      -9.9907   \n",
       "\n",
       "   run_trades  run_win_rate_pct  run_profit_factor   run_sqn  \\\n",
       "0          77          1.298701           0.778577 -0.286464   \n",
       "1          77          1.298701           0.778577 -0.286464   \n",
       "2          77          1.298701           0.778577 -0.286464   \n",
       "3          77          1.298701           0.778577 -0.286464   \n",
       "4          77          1.298701           0.778577 -0.286464   \n",
       "\n",
       "  run_expectancy_pct  buy_hold_return_pct  run_index  \n",
       "0          -0.132974           -33.514111          0  \n",
       "1          -0.132974           -33.514111          0  \n",
       "2          -0.132974           -33.514111          0  \n",
       "3          -0.132974           -33.514111          0  \n",
       "4          -0.132974           -33.514111          0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv(\"../../data/outputs/fvg_bulk_master_dataset_SOL-USDC_1m.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5e5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"y_win_net\"    # 1 if profitable net of costs, else 0\n",
    "EARLY_STOP_ROUNDS = 50      # tweak if needed\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ccd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dtype fixes (safe conversions if present)\n",
    "for col in [\"EntryTimestamp\", \"ExitTimestamp\", \"SignalTimestamp\", \"fvg_timestamp\", \"start_ts\", \"end_ts\"]:\n",
    "    if col in df.columns:\n",
    "        # many of your timestamps are epoch ms\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = pd.to_datetime(df[col], unit=\"ms\", errors=\"coerce\")\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Make sure cv_month exists and is sortable (keep as string like \"2025-01\" if you have it)\n",
    "if \"cv_month\" not in df.columns:\n",
    "    # fallback: derive year-month from EntryTimestamp\n",
    "    if \"EntryTimestamp\" in df.columns:\n",
    "        df[\"cv_month\"] = df[\"EntryTimestamp\"].dt.to_period(\"M\").astype(str)\n",
    "    else:\n",
    "        raise ValueError(\"cv_month or EntryTimestamp required for time-based CV.\")\n",
    "\n",
    "# Target\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found.\")\n",
    "y = df[TARGET_COL].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f73d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2) DROP LEAKAGE ----------\n",
    "leak_cols = [\n",
    "    # post-entry outcomes / future info\n",
    "    \"ExitIdx\",\"ExitTimestamp\",\"ExitPrice\",\"PnL\",\"PnL_net\",\"y_win_gross\",\"realized_R\",\n",
    "    \"holding_bars\",\"Commission\",\n",
    "    # run-level performance over the whole period (definite leakage)\n",
    "    \"run_return_ann_pct\",\"run_vol_ann_pct\",\"run_cagr_pct\",\"run_sharpe\",\"run_sortino\",\n",
    "    \"run_calmar\",\"run_mdd_pct\",\"run_trades\",\"run_win_rate_pct\",\"run_profit_factor\",\n",
    "    \"run_sqn\",\"run_expectancy_pct\",\"buy_hold_return_pct\",\n",
    "    # IDs / mostly constants / CV helpers\n",
    "    \"TradeId\",\"Tag\",\"run_id\",\"strategy_name\",\"symbol\",\"timeframe\",\n",
    "    \"start_ts\",\"end_ts\",\"run_index\",\n",
    "]\n",
    "\n",
    "drop_these = [c for c in leak_cols if c in df.columns]\n",
    "X = df.drop(columns=drop_these + [TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee22612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3) FEATURE SELECTION (keep only safe/useful cols if present) ----------\n",
    "# Keep features known at signal/entry time (includes your FVG params)\n",
    "whitelist = [\n",
    "    # market/entry context\n",
    "    \"Direction\",\"EntryIdx\",\"EntryPrice\",\"Size\",\"SL\",\"TP\",\"planned_R\",\n",
    "    \"SignalIdx\",\"signal_to_entry_delay_bars\",\n",
    "    # fvg geometry/quality\n",
    "    \"fvg_bar_index\",\"fvg_is_bull\",\"fvg_max_price\",\"fvg_min_price\",\"fvg_midpoint\",\n",
    "    \"fvg_gap_size_percent\",\"fvg_displacement_strength\",\n",
    "    \"fvg_age_bars\",\"zone_width_abs\",\"zone_width_pct\",\"matched_zone\",\n",
    "    \"entry_pos_in_zone\",\"signed_entry_pos\",\n",
    "    # HTF bias\n",
    "    \"htf_bull_count\",\"htf_bear_count\",\"htf_neutral_count\",\n",
    "    \"htf_bull_ratio\",\"htf_bear_ratio\",\"htf_all_bullish\",\"htf_all_bearish\",\n",
    "    \"htf_any_bullish\",\"htf_any_bearish\",\n",
    "    # time features (coarse)\n",
    "    \"hour_of_day\",\"day_of_week\",\"is_weekend\",\n",
    "    # run parameters (the tunable dials)\n",
    "    \"max_fvg_age\",\"fvg_threshold\",\"profit_target\",\"loss_target\",\n",
    "    \"commission_rate\",\"slippage_rate\",\n",
    "    \"position_sizing_rule\",\"position_fraction\",\"max_concurrent_trades\",\n",
    "    # optional HTF EMAs if you want them (will one-hot later or just treat numeric)\n",
    "    \"ema_htf_6h\",\"ema_htf_1h\",\"ema_htf_30m\",\"ema_htf_15m\",\"ema_htf_5m\",\n",
    "]\n",
    "\n",
    "present = [c for c in whitelist if c in X.columns]\n",
    "X = X[present].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fa2adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5301/1693922266.py:35: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  X = X.replace([np.inf, -np.inf], np.nan).fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4) LIGHT ENCODING (fixed for new sklearn) ----------\n",
    "# Booleans we want as categoricals if present\n",
    "bool_as_cat = []\n",
    "for c in [\"fvg_is_bull\", \"matched_zone\", \"is_weekend\"]:\n",
    "    if c in X.columns:\n",
    "        X[c] = X[c].astype(\"bool\")\n",
    "        bool_as_cat.append(c)\n",
    "\n",
    "# Auto-detect other categoricals (object/string)\n",
    "auto_cat = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "\n",
    "# Make sure this is string (categorical)\n",
    "if \"position_sizing_rule\" in X.columns and \"position_sizing_rule\" not in auto_cat:\n",
    "    X[\"position_sizing_rule\"] = X[\"position_sizing_rule\"].astype(str)\n",
    "    auto_cat.append(\"position_sizing_rule\")\n",
    "\n",
    "cat_cols = list(dict.fromkeys(bool_as_cat + auto_cat))  # unique, keep order\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "if cat_cols:\n",
    "    # sklearn >=1.2 uses 'sparse_output'; try it, fall back for older versions\n",
    "    try:\n",
    "        ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")  # older sklearn\n",
    "\n",
    "    ohe_arr = ohe.fit_transform(X[cat_cols])\n",
    "    ohe_cols = ohe.get_feature_names_out(cat_cols)\n",
    "    X_enc = pd.DataFrame(ohe_arr, columns=ohe_cols, index=X.index)\n",
    "    X = pd.concat([X[num_cols], X_enc], axis=1)\n",
    "else:\n",
    "    ohe = None\n",
    "\n",
    "# Clean up bad values and fill NAs\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3224cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5) FORWARD-CHAINING BY MONTH ----------\n",
    "months = sorted(X.index.to_series().map(df[\"cv_month\"]).unique())\n",
    "# Build folds: train on all months before m_k, validate on m_k\n",
    "folds = []\n",
    "for k in range(1, len(months)):\n",
    "    val_month = months[k]\n",
    "    train_months = months[:k]\n",
    "    trn_idx = df.index[df[\"cv_month\"].isin(train_months)]\n",
    "    val_idx = df.index[df[\"cv_month\"] == val_month]\n",
    "    if len(trn_idx) > 0 and len(val_idx) > 50:  # require some minimum\n",
    "        folds.append((trn_idx, val_idx))\n",
    "\n",
    "if not folds:\n",
    "    raise ValueError(\"Not enough distinct months to create forward-chaining folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26937b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Early stopping via callback (XGBoost ≥2.0)\u001b[39;00m\n\u001b[32m     32\u001b[39m es = xgb.callback.EarlyStopping(rounds=EARLY_STOP_ROUNDS, save_best=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# predictions\u001b[39;00m\n\u001b[32m     36\u001b[39m p = model.predict_proba(X_va)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/backtester-wK6PIE3F-py3.12/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: XGBClassifier.fit() got an unexpected keyword argument 'callbacks'"
     ]
    }
   ],
   "source": [
    "# ---------- 6) RUN FOLDS (fixed: use callback-based early stopping) ----------\n",
    "reports = []\n",
    "feat_importance_gain = defaultdict(float)\n",
    "\n",
    "for fold_num, (trn_idx, val_idx) in enumerate(folds, start=1):\n",
    "    X_tr, y_tr = X.loc[trn_idx], y.loc[trn_idx]\n",
    "    X_va, y_va = X.loc[val_idx], y.loc[val_idx]\n",
    "\n",
    "    # class imbalance\n",
    "    n_pos = int(y_tr.sum())\n",
    "    n_neg = int((y_tr == 0).sum())\n",
    "    spw = (n_neg / max(n_pos, 1)) if n_pos > 0 else 1.0\n",
    "\n",
    "    dtr = xgb.DMatrix(X_tr, label=y_tr, feature_names=X.columns.tolist())\n",
    "    dva = xgb.DMatrix(X_va, label=y_va, feature_names=X.columns.tolist())\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",            # \"gpu_hist\" if you have GPU\n",
    "        \"max_depth\": 6,\n",
    "        \"min_child_weight\": 4,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 1.0,\n",
    "        \"lambda\": 2.0,                    # reg_lambda\n",
    "        \"eta\": 0.08,                      # learning_rate\n",
    "        \"scale_pos_weight\": spw,\n",
    "        \"verbosity\": 0,\n",
    "    }\n",
    "\n",
    "    watchlist = [(dtr, \"train\"), (dva, \"valid\")]\n",
    "    booster = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtr,\n",
    "        num_boost_round=2000,\n",
    "        evals=watchlist,\n",
    "        early_stopping_rounds=EARLY_STOP_ROUNDS,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # predictions using best iteration\n",
    "    try:\n",
    "        p = booster.predict(dva, iteration_range=(0, booster.best_iteration + 1))\n",
    "    except TypeError:\n",
    "        # older xgboost\n",
    "        p = booster.predict(dva, ntree_limit=booster.best_ntree_limit)\n",
    "\n",
    "    yhat = (p >= 0.5).astype(int)\n",
    "\n",
    "    # metrics\n",
    "    ap = average_precision_score(y_va, p)\n",
    "    roc = roc_auc_score(y_va, p)\n",
    "    cm = confusion_matrix(y_va, yhat)\n",
    "    rep = classification_report(y_va, yhat, digits=3)\n",
    "\n",
    "    reports.append({\n",
    "        \"fold\": fold_num,\n",
    "        \"train_months\": months[:fold_num],\n",
    "        \"val_month\": months[fold_num],\n",
    "        \"n_train\": len(trn_idx),\n",
    "        \"n_val\": len(val_idx),\n",
    "        \"auc_pr\": ap,\n",
    "        \"roc_auc\": roc,\n",
    "        \"cm\": cm.tolist(),\n",
    "        \"report\": rep\n",
    "    })\n",
    "\n",
    "    # feature importance by gain (keys are actual column names)\n",
    "    fmap = booster.get_score(importance_type=\"gain\")\n",
    "    for name, gain in fmap.items():\n",
    "        feat_importance_gain[name] += gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 7) PRINT RESULTS ----------\n",
    "print(\"\\n==== Forward-Chaining Results ====\")\n",
    "for r in reports:\n",
    "    print(f\"\\nFold {r['fold']} | train: {r['train_months']} -> val: {r['val_month']}\")\n",
    "    print(f\"n_train={r['n_train']:,}  n_val={r['n_val']:,}\")\n",
    "    print(f\"AUC-PR={r['auc_pr']:.4f} | ROC-AUC={r['roc_auc']:.4f}\")\n",
    "    print(\"Confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "    print(np.array(r[\"cm\"]))\n",
    "    print(\"Classification report:\")\n",
    "    print(r[\"report\"])\n",
    "\n",
    "# Top features by total gain across folds\n",
    "fi_sorted = sorted(feat_importance_gain.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\n==== Top 25 Features (total gain across folds) ====\")\n",
    "for name, val in fi_sorted[:25]:\n",
    "    print(f\"{name:30s}  {val:.2f}\")\n",
    "\n",
    "# Optional: quick sanity check on class balance\n",
    "pos_rate = y.mean()\n",
    "print(f\"\\nOverall positive rate (y=1): {pos_rate:.3f}\")\n",
    "# ===== end ====="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backtester-wK6PIE3F-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
